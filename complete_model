{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8457513,"sourceType":"datasetVersion","datasetId":5040936},{"sourceId":8473946,"sourceType":"datasetVersion","datasetId":5053204}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hi there, This is Harsh here, and the below is my model for the first task given.Here I have used a simple VGG16 CNN model for binary classification and identificaton of the tumor images. Further I have used the Keras Sequenstial API.","metadata":{}},{"cell_type":"markdown","source":"Here in the first cell all the relevant Python Libraries have been used in the model. Tensorflow has been used in this model.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.utils import to_categorical\n\n\n\n#Here I have defined the path directories for the training data set\n#Initially I was having some issues regarding the paths, as I was directly using the path of the\n#tumor identification directory rather than the specific file directories of the images and the csv file\n\n\nimage_dir_main = '/kaggle/input/tumor-identification/train-20240519T105908Z-001'\nimage_subdir = 'train'\ncsv_path = '/kaggle/input/tumor-identification/trainset.csv'\nlabels_df = pd.read_csv(csv_path)\n\n\n\n#Now here we have first created a new colum in the data frame named as tumor type,\n# And in the next line of code, There is a funciton in Tensorflow, which has been used to generate \n#batches of image data. The rescale here is used for convergence, and 20% of the data is used as \n#validation set\nlabels_df['tumor_presence'] = labels_df['tumor type'].apply(lambda x: 0 if x == 'no_tumor' else 1)\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\nx_col = 'image'\ny_cols = ['tumor_presence', 'tumor type']","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-23T14:03:41.362311Z","iopub.execute_input":"2024-05-23T14:03:41.362691Z","iopub.status.idle":"2024-05-23T14:03:41.376726Z","shell.execute_reply.started":"2024-05-23T14:03:41.362662Z","shell.execute_reply":"2024-05-23T14:03:41.375716Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#This piece of code explicitly converts the values in the in=mage columns to strings \n#Previously I was getting error while directly feed the train dataset to model \n#thus converted the values to string\nlabels_df['image'] = labels_df['image'].astype(str)\nlabels_df['tumor_presence'] = labels_df['tumor type'].apply(lambda x: 0 if x == 'no_tumor' else 1)\nx_col = 'image'\ny_cols = ['tumor_presence', 'tumor type']\n\n\n\n\n#This part checks if the updated image paths exist\nmissing_files = []\nfor image_filename in labels_df['image']:\n    image_path = os.path.join(image_dir_main, image_filename)\n    if not os.path.exists(image_path):\n        missing_files.append(image_path)\n        \n        \n        \n        \n# This code piece is a optional step, used to resolve the missing files issue\nmissing_files = []\nfor image_filename in labels_df['image']:\n    image_path = os.path.join(image_dir_main, image_filename)\n    if not os.path.exists(image_path):\n        missing_files.append(image_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:15:25.097043Z","iopub.execute_input":"2024-05-23T14:15:25.097405Z","iopub.status.idle":"2024-05-23T14:15:25.192547Z","shell.execute_reply.started":"2024-05-23T14:15:25.097377Z","shell.execute_reply":"2024-05-23T14:15:25.191232Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Now in this part, the model architucture of the CNN has been defined and compiled,using the \n#Keras python library\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\nmodel = Sequential()\n#the defining of the architucture begins by a stack layer, and then by creating a convolutioinal layer\n#of 32 ouput paths/channels.\n#ReLU is the activation function used in this.\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n#The Flatten layer function, flattens the 2d input to an single array(1d)\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(4, activation='softmax'))  # 4 output units for 4 classes of tumors\n\n\n# Here we have compiled the model, using the adam optimizer, and the loss function used is \n#categoriacal crossentropy for the multi class classification.\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:13:27.822926Z","iopub.execute_input":"2024-05-23T14:13:27.823982Z","iopub.status.idle":"2024-05-23T14:13:31.420954Z","shell.execute_reply.started":"2024-05-23T14:13:27.823923Z","shell.execute_reply":"2024-05-23T14:13:31.420144Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#The paths and the labels have been redifined again because the code was showing error again and again.\ncsv_path = '/kaggle/input/tumor-identification/trainset.csv'\nlabels_df = pd.read_csv(csv_path)\nlabels_df['image'] = labels_df['image'].astype(str).str.zfill(4) + '.jpg'\nlabels_df['image'] = '/kaggle/input/tumor-identification/train-20240519T105908Z-001/train/' + labels_df['image']\nlabels_df['tumor_presence'] = labels_df['tumor type'].apply(lambda x: '0' if x == 'no_tumor' else '1')\n\n\n#\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=labels_df,\n    directory='/kaggle/input/tumor-identification/train-20240519T105908Z-001',\n    x_col='image',\n    y_col='tumor type',  # Multi-class target\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',  # Use categorical for multi-class classification\n    subset='training'\n)\n\nvalidation_generator = datagen.flow_from_dataframe(\n    dataframe=labels_df,\n    directory='/kaggle/input/tumor-identification/train-20240519T105908Z-001',\n    x_col='image',\n    y_col='tumor type',  # Multi-class target\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',  # Use categorical for multi-class classification\n    subset='validation'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-23T14:26:16.238399Z","iopub.execute_input":"2024-05-23T14:26:16.238807Z","iopub.status.idle":"2024-05-23T14:26:18.973395Z","shell.execute_reply.started":"2024-05-23T14:26:16.238778Z","shell.execute_reply":"2024-05-23T14:26:18.972265Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Found 4592 validated image filenames belonging to 4 classes.\nFound 1148 validated image filenames belonging to 4 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dir = '/kaggle/input/tumor-identification/train-20240519T105908Z-001/train'\ntest_dir = '/kaggle/input/testdata/test'\ncsv_path = '/kaggle/input/tumor-identification/trainset.csv'\nlabels_df = pd.read_csv(csv_path)\n\n\nrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_files = [f for f in os.listdir(test_dir) if f.endswith('.jpg')]\n\nimport pandas as pd\n\n# Here we have created a DataFrame for test data\ntest_image_files = [f for f in test_files if f.endswith('.jpg')]\ntest_df = pd.DataFrame(test_image_files, columns=['image'])\ntest_df['image'] = 'test/' + test_df['image']","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:17:35.495842Z","iopub.execute_input":"2024-05-23T15:17:35.496232Z","iopub.status.idle":"2024-05-23T15:17:35.510874Z","shell.execute_reply.started":"2024-05-23T15:17:35.496202Z","shell.execute_reply":"2024-05-23T15:17:35.509636Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Test generator using flow_from_dataframe\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory='/kaggle/input/testdata',\n    x_col='image',\n    y_col=None,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=None,\n    shuffle=False\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:17:55.109721Z","iopub.execute_input":"2024-05-23T15:17:55.110254Z","iopub.status.idle":"2024-05-23T15:17:55.319154Z","shell.execute_reply.started":"2024-05-23T15:17:55.110214Z","shell.execute_reply":"2024-05-23T15:17:55.317865Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Found 394 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test generator using flow_from_dataframe\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory='/kaggle/input/testdata',\n    x_col='image',\n    y_col=None,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=None,\n    shuffle=False\n)\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=10,\n    validation_data=validation_generator,\n    validation_steps=len(validation_generator)\n)\n\n# Save the trained model\nmodel.save('/kaggle/working/my_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:18:07.347160Z","iopub.execute_input":"2024-05-23T15:18:07.347543Z","iopub.status.idle":"2024-05-23T15:39:20.984908Z","shell.execute_reply.started":"2024-05-23T15:18:07.347517Z","shell.execute_reply":"2024-05-23T15:39:20.983749Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Found 394 validated image filenames.\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 2s/step - accuracy: 0.5937 - loss: 0.4355 - val_accuracy: 0.8659 - val_loss: 0.1862\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 3/10\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 2s/step - accuracy: 0.9019 - loss: 0.1393 - val_accuracy: 0.9416 - val_loss: 0.0852\nEpoch 4/10\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 5/10\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 2s/step - accuracy: 0.9805 - loss: 0.0422 - val_accuracy: 0.9774 - val_loss: 0.0487\nEpoch 6/10\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 7/10\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 2s/step - accuracy: 0.9914 - loss: 0.0197 - val_accuracy: 0.9791 - val_loss: 0.0570\nEpoch 8/10\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\nEpoch 9/10\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 2s/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9730 - val_loss: 0.0491\nEpoch 10/10\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = model.predict(test_generator, steps=len(test_generator), verbose=1)\npredicted_classes = (predictions > 0.5).astype(int).reshape(-1)\n\n\n\n\n\n\npredicted_classes = np.argmax(predictions, axis=1)\nfilenames = test_generator.filenames\nlabel_map = {0: 'no_tumor', 1: 'pituitary_tumor', 2: 'glioma_tumor', 3: 'meningioma_tumor'}\npredicted_labels = [label_map[class_idx] for class_idx in predicted_classes]\n\n\n\n\n\nresults_df = pd.DataFrame({'image': filenames, 'tumor type': predicted_labels})\nresults_df.to_csv('/kaggle/working/test_results.csv', index=False)\nprint(\"Results saved to test_results.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:44:39.330888Z","iopub.execute_input":"2024-05-23T15:44:39.331332Z","iopub.status.idle":"2024-05-23T15:44:49.807747Z","shell.execute_reply.started":"2024-05-23T15:44:39.331304Z","shell.execute_reply":"2024-05-23T15:44:49.806629Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 450ms/step\nResults saved to test_results.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:45:53.052364Z","iopub.execute_input":"2024-05-23T15:45:53.052771Z","iopub.status.idle":"2024-05-23T15:45:53.061009Z","shell.execute_reply.started":"2024-05-23T15:45:53.052743Z","shell.execute_reply":"2024-05-23T15:45:53.060069Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:48:58.598669Z","iopub.execute_input":"2024-05-23T15:48:58.599314Z","iopub.status.idle":"2024-05-23T15:48:58.610810Z","shell.execute_reply.started":"2024-05-23T15:48:58.599282Z","shell.execute_reply":"2024-05-23T15:48:58.609978Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"\\","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:52:06.084843Z","iopub.execute_input":"2024-05-23T15:52:06.085880Z","iopub.status.idle":"2024-05-23T15:52:06.091799Z","shell.execute_reply.started":"2024-05-23T15:52:06.085840Z","shell.execute_reply":"2024-05-23T15:52:06.090572Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:52:16.170836Z","iopub.execute_input":"2024-05-23T15:52:16.171546Z","iopub.status.idle":"2024-05-23T15:52:16.344675Z","shell.execute_reply.started":"2024-05-23T15:52:16.171491Z","shell.execute_reply":"2024-05-23T15:52:16.343062Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"F1 Score: 0.0000\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[48], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Print classification report\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_labels\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2363\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2362\u001b[0m     longest_last_line_heading \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2363\u001b[0m     name_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2364\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(name_width, \u001b[38;5;28mlen\u001b[39m(longest_last_line_heading), digits)\n\u001b[1;32m   2365\u001b[0m     head_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m:>\u001b[39m\u001b[38;5;132;01m{width}\u001b[39;00m\u001b[38;5;124ms} \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:>9}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(headers)\n","\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"],"ename":"ValueError","evalue":"max() arg is an empty sequence","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-23T15:53:32.239168Z","iopub.execute_input":"2024-05-23T15:53:32.239559Z","iopub.status.idle":"2024-05-23T15:53:32.260264Z","shell.execute_reply.started":"2024-05-23T15:53:32.239528Z","shell.execute_reply":"2024-05-23T15:53:32.258902Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"F1 Score: 0.3333\n              precision    recall  f1-score   support\n\ntumor_type_A       0.50      0.50      0.50         2\ntumor_type_B       0.00      0.00      0.00         1\n\n    accuracy                           0.33         3\n   macro avg       0.25      0.25      0.25         3\nweighted avg       0.33      0.33      0.33         3\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}